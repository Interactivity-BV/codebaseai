"""
This script is designed to interact with the OpenAI API using a chain of runnables to process input data and generate AI responses. 
It utilizes environment variables for configuration and includes logging for error handling. The script is intended for use with 
the OpenAI GPT-4 model and requires an API key to function.

Modules:
- langchain_core.output_parsers: Provides output parsers for processing AI responses.
- langchain_core.runnables: Contains runnable components for building processing chains.
- langchain_openai: Interfaces with OpenAI's language models.
- sys, os: Standard Python modules for system operations and environment management.
- logging: Standard Python module for logging error messages.
- dotenv: Loads environment variables from a .env file.

Classes:
- None

Functions:
- run_chain: Executes a chain of runnables to process input data and generate an AI response.
"""

from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
import sys
import os
import logging
from dotenv import load_dotenv

load_dotenv()

# Create a logger object
logger = logging.getLogger(__name__)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.")
    sys.exit(1)

def run_chain(prompt, input_data, model_name="gpt-4o"):
    """
    Runs a chain of runnables with the given input data.

    Args:
        prompt (ChatPromptTemplate): The prompt template to use for generating the AI response.
        input_data (str): The input data to be processed by the chain.
        model_name (str): Open AI Model

    Returns:
        str: The response generated by the AI.

    Raises:
        Exception: If there is an error during the chain execution.

    Side Effects:
        - Logs an error message if the OpenAI API key is not found.
        - Exits the program if the API key is missing.

    Future Work:
        - Implement error handling for specific exceptions during chain execution.
        - Consider adding more detailed logging for debugging purposes.
    """
    response = ""
    try:
        llmOpenAI = ChatOpenAI(temperature=0.1, model_name=model_name, streaming=True, api_key=OPENAI_API_KEY)

        chain = (
            {"input": RunnablePassthrough()}
            | prompt  
            | llmOpenAI
            | StrOutputParser()
        )
        response = chain.invoke(input_data)
    except Exception as e:
        logger.error(f"Error during large language model execution: {e}")
        sys.exit
    return response