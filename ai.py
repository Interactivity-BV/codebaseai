from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
import sys
import os
import logging
from dotenv import load_dotenv

load_dotenv()

# Create a logger object
logger = logging.getLogger(__name__)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.error("OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.")
    sys.exit(1)

llmOpenAI = ChatOpenAI(temperature=0.1, model_name="gpt-4o", streaming=True, api_key=OPENAI_API_KEY)

def run_chain(prompt, input_data):
    """
    Runs a chain of runnables with the given input data.

    Args:
        prompt (ChatPromptTemplate): The prompt template to use for generating the AI response.
        input_data (str): The input data to be processed by the chain.

    Returns:
        str: The response generated by the AI.

    Raises:
        Exception: If there is an error during the chain execution.
    """
    chain = (
        {"input": RunnablePassthrough()}
        | prompt  
        | llmOpenAI
        | StrOutputParser()
    )
    response = chain.invoke(input_data)
    return response